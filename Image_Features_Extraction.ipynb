{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Image_Features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HntIesxSQ2_1"
      },
      "source": [
        "### Create Directories to Store Images Based on the Keras Preprocessing Directory Format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9qoZjCWC5UK"
      },
      "source": [
        "!mkdir /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B2Uk812C8j1"
      },
      "source": [
        "!mkdir /content/data/train_image\n",
        "!mkdir /content/data/test_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs6XkIWfDLp2"
      },
      "source": [
        "%cd /content/data/train_image\n",
        "%cp -av /content/drive/MyDrive/FloodNet_Track2/Images/Train_Image Train_Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebp5I2849F_m"
      },
      "source": [
        "%cd /content/data/test_image\n",
        "%cp -av /content/drive/MyDrive/FloodNet_Track2/Images/Test_Image test_Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYSn8C5klarM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import json\n",
        "from pathlib import Path\n",
        "import regex as re\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import spacy\n",
        "import scipy.io\n",
        "import gc\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "from PIL import Image\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation, Reshape, Flatten\n",
        "from keras import Input\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import concatenate\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import model_from_json, Model\n",
        "from keras.utils import plot_model\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "from keras.utils import np_utils, generic_utils\n",
        "from progressbar import Bar, ETA, Percentage, ProgressBar\n",
        "from itertools import zip_longest\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory, text_dataset_from_directory\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrKoRstrjUNM",
        "outputId": "4ac582be-f95f-44f3-a8ef-25b9ab9fb52e"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\"/content/data/train_image\",\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)\n",
        "test_dataset = image_dataset_from_directory(\"/content/data/test_image\",\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1448 files belonging to 1 classes.\n",
            "Found 450 files belonging to 1 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnk6FrqWkHgZ"
      },
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJsslJsxRUIJ"
      },
      "source": [
        "### Define Layers in the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NpUP5zskIzj"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx-VV0wSkbWc"
      },
      "source": [
        "preprocess_input = tf.keras.applications.vgg16.preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHyrhr1GaVey"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STQvlcz_aY5U"
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GuH1UmkRdHa"
      },
      "source": [
        "### Import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3vzo_oHaLWs",
        "outputId": "067daff7-55d4-4df4-effd-ffc8f0424ac1"
      },
      "source": [
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sJ90PZDaU5g"
      },
      "source": [
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKjZTVokgxNI",
        "outputId": "06cf9b14-e928-4482-f696-41890e51afab"
      },
      "source": [
        "print(\"Number of layers in the base model: \", len(base_model.layers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers in the base model:  19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIvqdn9KRjPd"
      },
      "source": [
        "### Freeze Specific Layers for Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA2uTntSgzlv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eed863c3-2f0b-4df8-f06f-9db71225c52d"
      },
      "source": [
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 11\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False\n",
        "\n",
        "for layer in base_model.layers:\n",
        "  sp = '   '[len(layer.name):]\n",
        "  print(layer.name, sp, layer.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_1  False\n",
            "block1_conv1  False\n",
            "block1_conv2  False\n",
            "block1_pool  False\n",
            "block2_conv1  False\n",
            "block2_conv2  False\n",
            "block2_pool  False\n",
            "block3_conv1  False\n",
            "block3_conv2  False\n",
            "block3_conv3  False\n",
            "block3_pool  False\n",
            "block4_conv1  True\n",
            "block4_conv2  True\n",
            "block4_conv3  True\n",
            "block4_pool  True\n",
            "block5_conv1  True\n",
            "block5_conv2  True\n",
            "block5_conv3  True\n",
            "block5_pool  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_XJdVjRwtu"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjse-Am6acVJ"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff7AtxSia59-"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-e_AMtva67-",
        "outputId": "c8013af9-2dbd-49bf-910f-9baf3e19293d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem (Sl (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf.nn.bias_add (TFOpLambda)  (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 14,715,201\n",
            "Trainable params: 12,979,713\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsOYzG8tR1pN"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4P-ALlsa9n3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06bba81c-a1d7-4112-b4be-0f19c034d676"
      },
      "source": [
        "initial_epochs = 20\n",
        "\n",
        "save_model = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/Weights/vgg16.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs = initial_epochs,\n",
        "    validation_data = validation_dataset,\n",
        "    callbacks = [save_model]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/20\n",
            "362/362 [==============================] - 278s 763ms/step - loss: 1.6193e-12 - accuracy: 1.0000 - val_loss: 4.9999e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 1.00000, saving model to /content/drive/MyDrive/FloodNet Competition Notebooks/Weights/vgg16.h5\n",
            "Epoch 2/20\n",
            "362/362 [==============================] - 264s 716ms/step - loss: 7.5814e-12 - accuracy: 1.0000 - val_loss: 4.7437e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 1.00000\n",
            "Epoch 3/20\n",
            "362/362 [==============================] - 263s 713ms/step - loss: 5.3637e-13 - accuracy: 1.0000 - val_loss: 4.7285e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 1.00000\n",
            "Epoch 4/20\n",
            "362/362 [==============================] - 262s 711ms/step - loss: 1.0235e-12 - accuracy: 1.0000 - val_loss: 4.6877e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 1.00000\n",
            "Epoch 5/20\n",
            "362/362 [==============================] - 263s 712ms/step - loss: 1.8037e-12 - accuracy: 1.0000 - val_loss: 4.6221e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 1.00000\n",
            "Epoch 6/20\n",
            "362/362 [==============================] - 263s 715ms/step - loss: 3.1238e-12 - accuracy: 1.0000 - val_loss: 4.5170e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 1.00000\n",
            "Epoch 7/20\n",
            "362/362 [==============================] - 264s 718ms/step - loss: 5.2194e-13 - accuracy: 1.0000 - val_loss: 4.4978e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 1.00000\n",
            "Epoch 8/20\n",
            "362/362 [==============================] - 266s 721ms/step - loss: 1.0692e-11 - accuracy: 1.0000 - val_loss: 4.2343e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 1.00000\n",
            "Epoch 9/20\n",
            "362/362 [==============================] - 267s 723ms/step - loss: 1.4846e-12 - accuracy: 1.0000 - val_loss: 4.1920e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 1.00000\n",
            "Epoch 10/20\n",
            "362/362 [==============================] - 269s 729ms/step - loss: 3.3062e-12 - accuracy: 1.0000 - val_loss: 4.0847e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 1.00000\n",
            "Epoch 11/20\n",
            "362/362 [==============================] - 266s 721ms/step - loss: 3.7053e-11 - accuracy: 1.0000 - val_loss: 3.1336e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 1.00000\n",
            "Epoch 12/20\n",
            "362/362 [==============================] - 268s 726ms/step - loss: 9.8401e-13 - accuracy: 1.0000 - val_loss: 3.1169e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 1.00000\n",
            "Epoch 13/20\n",
            "362/362 [==============================] - 267s 725ms/step - loss: 2.1070e-12 - accuracy: 1.0000 - val_loss: 3.0853e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 1.00000\n",
            "Epoch 14/20\n",
            "362/362 [==============================] - 266s 723ms/step - loss: 3.0690e-12 - accuracy: 1.0000 - val_loss: 3.0355e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "Epoch 15/20\n",
            "362/362 [==============================] - 268s 726ms/step - loss: 7.9782e-13 - accuracy: 1.0000 - val_loss: 3.0151e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "Epoch 16/20\n",
            "362/362 [==============================] - 267s 724ms/step - loss: 3.2229e-12 - accuracy: 1.0000 - val_loss: 2.9621e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "Epoch 17/20\n",
            "362/362 [==============================] - 269s 731ms/step - loss: 1.4861e-12 - accuracy: 1.0000 - val_loss: 2.9340e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "Epoch 18/20\n",
            "362/362 [==============================] - 269s 730ms/step - loss: 8.4768e-12 - accuracy: 1.0000 - val_loss: 2.8158e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "Epoch 19/20\n",
            "362/362 [==============================] - 268s 727ms/step - loss: 1.6390e-13 - accuracy: 1.0000 - val_loss: 2.8139e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "Epoch 20/20\n",
            "362/362 [==============================] - 269s 730ms/step - loss: 1.7823e-10 - accuracy: 1.0000 - val_loss: 1.3126e-14 - val_accuracy: 1.0000\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5giELWPUG-f"
      },
      "source": [
        "### Modifying Model for Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxDxli45MZkb",
        "outputId": "750ef1de-4a95-4c88-da87-1a994735ed1b"
      },
      "source": [
        "import keras\n",
        "model = Sequential()\n",
        "reconstructed_model = keras.models.load_model(\"/content/drive/Weights/vgg16.h5\")\n",
        "for layer in reconstructed_model.layers[:5]: # go through until last layer\n",
        "    model = layer\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 12,979,200\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1T7o64EzIEU",
        "outputId": "ec682259-1d72-413a-a231-0d96429d7edd"
      },
      "source": [
        "import keras\n",
        "reconstructed_model = keras.models.load_model(\"/content/drive/Weights/vgg16.h5\")\n",
        "ip = Input([224, 224, 3])\n",
        "x = preprocess_input(ip)\n",
        "Model = Sequential()\n",
        "for layer in base_model.layers[:5]: \n",
        "    Model = layer\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Model)\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(4096))\n",
        "x = model1(x, training=True)\n",
        "\n",
        "model_ = tf.keras.Model(inputs=[ip], outputs=[x])\n",
        "model_.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf.__operators__.getitem_2 ( (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf.nn.bias_add_2 (TFOpLambda (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 4096)              117479232 \n",
            "=================================================================\n",
            "Total params: 117,479,232\n",
            "Trainable params: 115,743,744\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBHVcdOIUXUA"
      },
      "source": [
        "### Extract Image Features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi73p1YZ5jEk"
      },
      "source": [
        "image_list_train = []\n",
        "image_list_test = []\n",
        "for images, labels in train_dataset:\n",
        "  image_list_train.append(images)\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "  image_list_test.append(images) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlYgiQwektBO"
      },
      "source": [
        "image_features_train = []\n",
        "image_features_test = []\n",
        "for image in image_list_train:\n",
        "  image_features_train.append(model_(image))\n",
        "\n",
        "for image in image_list_test:\n",
        "  image_features_test.append(model_(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdodXdl4L7Aq",
        "outputId": "d8602f26-1ac1-4b05-d651-2f337dcafec9"
      },
      "source": [
        "train_img_features = np.transpose(np.vstack(image_features_train))\n",
        "test_img_features = np.transpose(np.vstack(image_features_test))\n",
        "print(test_img_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4096, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0EwabLgSR6X"
      },
      "source": [
        "### Store Image Features in the Required Format\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMg49o9FMW2e"
      },
      "source": [
        "import pickle\n",
        "features_train = open('/content/drive/Feature_Files/vgg_features_train.txt', 'wb')\n",
        "pickle.dump(train_img_features, features_train)\n",
        "features_train.close()\n",
        "\n",
        "features_test = open('/content/drive/Feature_Files/vgg_features_test.txt', 'wb')\n",
        "pickle.dump(test_img_features, features_test)\n",
        "features_test.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Naojm3xZPwUI",
        "outputId": "c1acd683-8fc1-4d33-9b6f-fae0e7390073"
      },
      "source": [
        "features = open('/content/drive/Feature_Files/vgg_features_test.txt',\"rb\")\n",
        "imgfam = pickle.load(features)\n",
        "print(imgfam.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4096, 450)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}